# Task 8.1: ãƒ­ã‚°åé›†æ©Ÿèƒ½å®Ÿè£… - è¨­è¨ˆæ›¸

**Issue**: MWD-53  
**ä½œæˆæ—¥**: 2026-02-17  
**æ›´æ–°æ—¥**: 2026-02-17 (Engineå´è¨­è¨ˆæ›¸ã‚’åæ˜ )  
**ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹**: Design Phase

---

## ğŸ“‹ ç›®æ¬¡

1. [æ¦‚è¦](#æ¦‚è¦)
2. [å‚ç…§è¨­è¨ˆæ›¸](#å‚ç…§è¨­è¨ˆæ›¸)
3. [ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£](#ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£)
4. [ãƒ­ã‚°åé›†ãƒ•ãƒ­ãƒ¼](#ãƒ­ã‚°åé›†ãƒ•ãƒ­ãƒ¼)
5. [ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­è¨ˆ](#ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­è¨ˆ)
6. [ãƒ‡ãƒ¼ã‚¿æ§‹é€ ](#ãƒ‡ãƒ¼ã‚¿æ§‹é€ )
7. [å®Ÿè£…è¨ˆç”»](#å®Ÿè£…è¨ˆç”»)
8. [ãƒ†ã‚¹ãƒˆè¨ˆç”»](#ãƒ†ã‚¹ãƒˆè¨ˆç”»)

---

## æ¦‚è¦

### ãªãœã‚„ã‚‹ã‹

WAFã‚¨ãƒ³ã‚¸ãƒ³ï¼ˆMrWebDefence-Engineï¼‰ã‹ã‚‰è»¢é€ã•ã‚Œã‚‹ãƒ­ã‚°ã‚’å—ä¿¡ã—ã€ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–ãƒ»ä¿å­˜ã™ã‚‹æ©Ÿèƒ½ãŒå¿…è¦ã€‚

### ä½•ã‚’ã‚„ã‚‹ã‹

- **ãƒ­ã‚°å—ä¿¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆå®Ÿè£…**ï¼ˆHTTPï¼‰
- **ãƒ­ã‚°ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–ãƒ­ã‚¸ãƒƒã‚¯å®Ÿè£…**
- **ãƒ­ã‚°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£æ©Ÿèƒ½å®Ÿè£…**
- **ãƒ­ã‚°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ©Ÿèƒ½å®Ÿè£…**
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸å®Ÿè£…**ï¼ˆåˆæœŸ: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ï¼‰

### å—ã‘å…¥ã‚Œæ¡ä»¶

- [ ] ãƒ­ã‚°å—ä¿¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- [ ] ãƒ­ã‚°ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- [ ] ãƒ­ã‚°ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- [ ] ãƒ­ã‚°ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹
- [ ] ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¸ã®ä¿å­˜ãŒæ­£å¸¸ã«å‹•ä½œã™ã‚‹

---

## å‚ç…§è¨­è¨ˆæ›¸

æœ¬è¨­è¨ˆã¯ã€MrWebDefence-Engineã®ãƒ­ã‚°è»¢é€è¨­è¨ˆã¨é€£æºã—ã¾ã™ï¼š

- **[MWD-40: Fluentdè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–è¨ˆç”»](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-fluentd-modularization-plan.md)**
  - Engineå´ã®Fluentdè¨­å®šæ§‹é€ 
  - label/includeã‚’ä½¿ã£ãŸãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–æ–¹é‡
  
- **[MWD-40: ãƒ­ã‚°è»¢é€æ©Ÿèƒ½å®Ÿè£… å®Ÿè£…è¨­è¨ˆæ›¸](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-implementation-plan.md)**
  - ãƒ­ã‚°å½¢å¼ã€ã‚¿ã‚°è¨­è¨ˆ
  - ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆcustomer_nameã€fqdnã€year/month/day/hourç­‰ï¼‰
  - è»¢é€ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆä»•æ§˜
  
- **[MWD-40: ãƒ­ã‚°é€£æºæ–¹æ³•æ¯”è¼ƒæ¤œè¨](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-log-integration-analysis.md)**
  - å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ æ–¹å¼ vs ãƒ­ã‚°ãƒ‰ãƒ©ã‚¤ãƒæ–¹å¼
  - æ¨å¥¨æ–¹å¼: å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ æ–¹å¼ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆï¼‰

---

## ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£

### å…¨ä½“æ§‹æˆ

```mermaid
graph TB
    subgraph Engine["MrWebDefence-Engine"]
        WAF[WAF Engine<br/>Nginx + OpenAppSec]
        EngineFluentd[Fluentd]
        WAF -->|ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«<br/>å…±æœ‰ãƒœãƒªãƒ¥ãƒ¼ãƒ | EngineFluentd
    end
    
    subgraph LogServer["MrWebDefence-LogServer"]
        Endpoint[Log Receiver<br/>FastAPI]
        Parser[Log Parser]
        Normalizer[Normalizer]
        TimeCorrector[Time Corrector]
        Buffer[Log Buffer]
        Storage[File Storage]
        
        Endpoint -->|HTTP POST| Parser
        Parser -->|ãƒ‘ãƒ¼ã‚¹| Normalizer
        Normalizer -->|æ­£è¦åŒ–| TimeCorrector
        TimeCorrector -->|è£œæ­£| Buffer
        Buffer -->|éåŒæœŸ<br/>ãƒãƒƒãƒæ›¸ãè¾¼ã¿| Storage
    end
    
    EngineFluentd -->|HTTP/JSON| Endpoint
```

### Engineå´ã‹ã‚‰ã®è»¢é€å½¢å¼

Engineå´ã®Fluentdã‹ã‚‰ä»¥ä¸‹ã®å½¢å¼ã§ãƒ­ã‚°ãŒè»¢é€ã•ã‚Œã¾ã™ï¼š

#### Nginxã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°

**ã‚¿ã‚°**: `nginx.access`ï¼ˆEngineå´ã®ã‚¿ã‚°è¨­è¨ˆã«æº–æ‹ ï¼‰

**ãƒ¬ã‚³ãƒ¼ãƒ‰æ§‹é€ **:
```json
{
  "time": "2026-02-17T13:30:00+09:00",
  "remote_addr": "192.168.1.100",
  "request": "GET /api/users HTTP/1.1",
  "status": 200,
  "body_bytes_sent": 1234,
  "request_time": 0.123,
  "host": "example.com",
  "customer_name": "customer-a",
  "log_type": "nginx",
  "hostname": "waf-engine-01",
  "fqdn": "example.com",
  "year": "2026",
  "month": "02",
  "day": "17",
  "hour": "13",
  "minute": "30",
  "second": "45"
}
```

#### OpenAppSecæ¤œçŸ¥ãƒ­ã‚°

**ã‚¿ã‚°**: `openappsec.detection`ï¼ˆEngineå´ã®ã‚¿ã‚°è¨­è¨ˆã«æº–æ‹ ï¼‰

**ãƒ¬ã‚³ãƒ¼ãƒ‰æ§‹é€ **:
```json
{
  "time": "2026-02-17T13:30:00+09:00",
  "host": "example.com",
  "protectionName": "Threat Prevention Basic",
  "signature": "SQL Injection Attempt",
  "ruleName": "rule_001",
  "sourceIP": "192.168.1.100",
  "requestUri": "/admin/login",
  "log_type": "openappsec",
  "source": "waf-engine",
  "hostname": "waf-engine-01",
  "customer_name": "customer-a",
  "fqdn": "example.com",
  "year": "2026",
  "month": "02",
  "day": "17",
  "hour": "13",
  "minute": "30",
  "second": "45"
}
```

### æŠ€è¡“ã‚¹ã‚¿ãƒƒã‚¯

- **ãƒ­ã‚°å—ä¿¡**: Python (FastAPI)
- **ãƒ‡ãƒ¼ã‚¿å‡¦ç†**: Python
- **éåŒæœŸI/O**: aiofiles, asyncio
- **ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: File Systemï¼ˆåˆæœŸï¼‰/ Databaseï¼ˆå°†æ¥ï¼‰

---

## ãƒ­ã‚°åé›†ãƒ•ãƒ­ãƒ¼

### ã‚·ãƒ¼ã‚±ãƒ³ã‚¹å›³

```mermaid
sequenceDiagram
    participant EF as Engine Fluentd
    participant LR as Log Receiver
    participant P as Parser
    participant N as Normalizer
    participant TC as Time Corrector
    participant B as Buffer
    participant S as Storage

    EF->>LR: HTTP POST /api/logs (JSON)
    LR->>P: ãƒ­ã‚°ãƒ‡ãƒ¼ã‚¿
    P->>P: ãƒ‘ãƒ¼ã‚¹ãƒ»æ¤œè¨¼
    P->>N: ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ­ã‚°
    N->>N: æ­£è¦åŒ–
    N->>TC: æ­£è¦åŒ–æ¸ˆã¿ãƒ­ã‚°
    TC->>TC: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£
    TC->>B: è£œæ­£æ¸ˆã¿ãƒ­ã‚°
    B->>B: ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
    LR-->>EF: 200 OK (å³åº§ã«å¿œç­”)
    
    Note over B,S: éåŒæœŸå‡¦ç†
    B->>B: ãƒ•ãƒ©ãƒƒã‚·ãƒ¥æ¡ä»¶ãƒã‚§ãƒƒã‚¯<br/>(ã‚µã‚¤ã‚ºãƒ»æ™‚é–“)
    B->>S: ãƒãƒƒãƒæ›¸ãè¾¼ã¿<br/>(aiofilesä½¿ç”¨)
```

### ãƒ•ãƒ­ãƒ¼èª¬æ˜

1. **ãƒ­ã‚°å—ä¿¡**: Engine Fluentdã‹ã‚‰HTTP POSTã§ãƒ­ã‚°ã‚’å—ä¿¡ï¼ˆJSONå½¢å¼ï¼‰
2. **ãƒ‘ãƒ¼ã‚¹**: JSONå½¢å¼ã®ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹ãƒ»å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¤œè¨¼
3. **æ­£è¦åŒ–**: LogServerã®å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆLogEntryï¼‰ã«å¤‰æ›
4. **ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£**: ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³å¤‰æ›ã€æ¬ æè£œå®Œã€æœªæ¥æ™‚åˆ»è£œæ­£
5. **ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°**: ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ å¾Œã€**å³åº§ã«200 OKã‚’è¿”ã™**ï¼ˆéåŒæœŸå‡¦ç†ï¼‰
6. **æ°¸ç¶šåŒ–**: ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§éåŒæœŸã«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«ä¿å­˜ï¼ˆãƒ•ãƒ©ãƒƒã‚·ãƒ¥æ¡ä»¶: ã‚µã‚¤ã‚ºãƒ»æ™‚é–“ï¼‰

---

## ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆè¨­è¨ˆ

### 1. Log Receiverï¼ˆå—ä¿¡ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼‰

#### APIã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**POST /api/logs**

Engine Fluentdã‹ã‚‰ä»¥ä¸‹ã®å½¢å¼ã§ãƒ­ã‚°ã‚’å—ä¿¡ï¼š

- **å˜ä¸€ãƒ­ã‚°**: 1ã¤ã®JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆ
- **ãƒãƒƒãƒãƒ­ã‚°**: JSONã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®é…åˆ—

ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹ï¼ˆå˜ä¸€ãƒ­ã‚°ï¼‰:
```json
{
  "time": "2026-02-17T13:30:00.123+09:00",
  "log_type": "nginx",
  "hostname": "waf-engine-01",
  "customer_name": "customer-a",
  "fqdn": "example.com",
  "remote_addr": "192.168.1.100",
  "request": "GET /api/users HTTP/1.1",
  "status": 200
}
```

ãƒªã‚¯ã‚¨ã‚¹ãƒˆä¾‹ï¼ˆãƒãƒƒãƒãƒ­ã‚°ï¼‰:
```json
[
  { "time": "...", "log_type": "nginx", ... },
  { "time": "...", "log_type": "nginx", ... },
  { "time": "...", "log_type": "openappsec", ... }
]
```

ãƒ¬ã‚¹ãƒãƒ³ã‚¹:
```json
{
  "status": "success",
  "received": 3,
  "timestamp": "2026-02-17T13:30:00.456+09:00"
}
```

**GET /health**

ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆï¼š

```json
{
  "status": "healthy",
  "buffer_size": 42,
  "timestamp": "2026-02-17T13:30:00.123Z"
}
```

#### å®Ÿè£…ä¾‹

```python
from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import List, Dict, Any, Union
from datetime import datetime
from contextlib import asynccontextmanager

@asynccontextmanager
async def lifespan(app: FastAPI):
    """ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®ãƒ©ã‚¤ãƒ•ã‚µã‚¤ã‚¯ãƒ«ç®¡ç†"""
    # èµ·å‹•æ™‚
    print("ğŸš€ MrWebDefence Log Server starting...")
    yield
    # çµ‚äº†æ™‚
    print("ğŸ›‘ MrWebDefence Log Server shutting down...")
    await log_buffer.close()  # ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥

app = FastAPI(
    title="MrWebDefence Log Server",
    description="WAFãƒ­ã‚°åé›†ãƒ»ç®¡ç†ã‚µãƒ¼ãƒãƒ¼",
    version="0.1.0",
    lifespan=lifespan,
)

class EngineLog(BaseModel):
    """Engineå´ã‹ã‚‰é€ä¿¡ã•ã‚Œã‚‹ãƒ­ã‚°"""
    time: str
    log_type: str
    hostname: str
    customer_name: str
    fqdn: str
    # ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¯å‹•çš„ã«å—ã‘ä»˜ã‘ã‚‹
    
    class Config:
        extra = "allow"  # è¿½åŠ ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¨±å¯

@app.post("/api/logs")
async def receive_logs(logs: Union[EngineLog, List[EngineLog]]):
    """
    Engine Fluentdã‹ã‚‰ãƒ­ã‚°ã‚’å—ä¿¡
    
    - å˜ä¸€ãƒ­ã‚°ã¾ãŸã¯ãƒãƒƒãƒãƒ­ã‚°ã‚’å—ã‘ä»˜ã‘
    - ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–ãƒ»è£œæ­£å¾Œã€ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
    - å³åº§ã«200 OKã‚’è¿”ã™ï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ›¸ãè¾¼ã¿ã¯éåŒæœŸï¼‰
    - ãƒãƒƒãƒ•ã‚¡ãŒæº€æ¯ã®å ´åˆã¯503 Service Unavailableã‚’è¿”ã™
    """
    # å˜ä¸€ãƒ­ã‚°ã®å ´åˆã¯ãƒªã‚¹ãƒˆã«å¤‰æ›
    if not isinstance(logs, list):
        logs = [logs]
    
    try:
        # ãƒ‘ãƒ¼ã‚¹ãƒ»æ­£è¦åŒ–ãƒ»è£œæ­£
        processed_logs = []
        for log in logs:
            try:
                # Engineå´ã®ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹
                parsed = parser.parse(log.dict())
                
                # æ­£è¦åŒ–
                log_entry = normalizer.normalize(parsed)
                
                # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£
                log_entry = time_corrector.correct(log_entry)
                
                processed_logs.append(log_entry)
            except ValueError as e:
                # å€‹åˆ¥ãƒ­ã‚°ã®ãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã«è¨˜éŒ²ã—ã¦ç¶šè¡Œ
                logger.warning(f"Failed to parse log: {e}, log: {log.dict()}")
                continue
        
        # ã™ã¹ã¦ã®ãƒ­ã‚°ãŒãƒ‘ãƒ¼ã‚¹å¤±æ•—ã—ãŸå ´åˆ
        if not processed_logs:
            raise HTTPException(
                status_code=400,
                detail="All logs failed to parse"
            )
        
        # ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ ï¼ˆéåŒæœŸã€å³åº§ã«ãƒªã‚¿ãƒ¼ãƒ³ï¼‰
        await log_buffer.add_batch(processed_logs)
        
        return {
            "status": "success",
            "received": len(processed_logs),
            "timestamp": datetime.utcnow().isoformat()
        }
    except BufferFullError as e:
        # ãƒãƒƒãƒ•ã‚¡æº€æ¯ã®å ´åˆã¯503ã‚’è¿”ã™ï¼ˆãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ï¼‰
        logger.warning(f"Buffer full: {e}")
        raise HTTPException(
            status_code=503,
            detail=f"Buffer is full, please retry later: {str(e)}"
        )
    except HTTPException:
        # HTTPExceptionã¯ãã®ã¾ã¾å†é€å‡º
        raise
    except Exception as e:
        # äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã¯ãƒ­ã‚°ã«è¨˜éŒ²
        logger.error(f"Unexpected error in receive_logs: {e}", exc_info=True)
        raise HTTPException(status_code=500, detail="Internal server error")

@app.get("/health")
async def health_check():
    """ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯"""
    return {
        "status": "healthy",
        "buffer_size": log_buffer.size(),
        "timestamp": datetime.utcnow().isoformat()
    }
```

### 2. Log Parser

#### å½¹å‰²

Engineå´ã‹ã‚‰é€ä¿¡ã•ã‚Œã‚‹ãƒ­ã‚°ã‚’æ¤œè¨¼ãƒ»ãƒ‘ãƒ¼ã‚¹ï¼š

- JSONå½¢å¼ã®æ¤œè¨¼
- å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèªï¼ˆtimeã€log_typeã€hostnameã€fqdnï¼‰
- ãƒ‡ãƒ¼ã‚¿å‹ã®æ¤œè¨¼
- ä¸æ­£ãªãƒ‡ãƒ¼ã‚¿ã®æ‹’å¦

#### å®Ÿè£…ä¾‹

```python
class LogParser:
    """Engineå´ã®ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹"""
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    REQUIRED_FIELDS = ['time', 'log_type', 'hostname', 'fqdn']
    
    # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®æœ€å¤§é•·ï¼ˆDoSæ”»æ’ƒå¯¾ç­–ï¼‰
    MAX_FIELD_LENGTH = 1024
    MAX_MESSAGE_LENGTH = 10240  # 10KB
    
    def parse(self, engine_log: dict) -> dict:
        """
        Engineå´ã®ãƒ­ã‚°ã‚’æ¤œè¨¼ãƒ»ãƒ‘ãƒ¼ã‚¹
        
        Args:
            engine_log: Engineå´ã®ãƒ­ã‚°è¾æ›¸
            
        Returns:
            æ¤œè¨¼æ¸ˆã¿ãƒ­ã‚°è¾æ›¸
            
        Raises:
            ValueError: å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒæ¬ ã‘ã¦ã„ã‚‹ã€ã¾ãŸã¯ä¸æ­£ãªå€¤ã®å ´åˆ
        """
        # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ç¢ºèª
        for field in self.REQUIRED_FIELDS:
            if field not in engine_log or engine_log[field] is None:
                raise ValueError(f"Missing required field: {field}")
        
        # ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®å‹ã¨é•·ã•ã®æ¤œè¨¼ï¼ˆã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å¯¾ç­–ï¼‰
        for field in self.REQUIRED_FIELDS:
            value = engine_log[field]
            if not isinstance(value, str):
                raise ValueError(f"Field {field} must be a string, got {type(value)}")
            if len(value) > self.MAX_FIELD_LENGTH:
                raise ValueError(f"Field {field} exceeds maximum length of {self.MAX_FIELD_LENGTH}")
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®é•·ã•æ¤œè¨¼ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        if 'message' in engine_log and isinstance(engine_log['message'], str):
            if len(engine_log['message']) > self.MAX_MESSAGE_LENGTH:
                raise ValueError(f"Message exceeds maximum length of {self.MAX_MESSAGE_LENGTH}")
        
        return engine_log
```

### 3. Normalizerï¼ˆæ­£è¦åŒ–ï¼‰

#### å½¹å‰²

Engineå´ã®ãƒ­ã‚°ã‚’LogServerã®å†…éƒ¨ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆLogEntryï¼‰ã«å¤‰æ›ï¼š

- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®datetimeå¤‰æ›
- ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®æ­£è¦åŒ–
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŠ½å‡º
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†

#### å®Ÿè£…ä¾‹

```python
class LogNormalizer:
    """Engineå´ã®ãƒ­ã‚°ã‚’LogServerã®ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ã«æ­£è¦åŒ–"""
    
    LEVEL_MAP = {
        "debug": "debug",
        "info": "info",
        "warn": "warning",
        "warning": "warning",
        "error": "error",
        "critical": "critical",
    }
    
    def normalize(self, engine_log: dict) -> LogEntry:
        """
        Engineå´ã®ãƒ­ã‚°ã‚’æ­£è¦åŒ–
        
        Args:
            engine_log: ãƒ‘ãƒ¼ã‚¹æ¸ˆã¿ãƒ­ã‚°è¾æ›¸
            
        Returns:
            æ­£è¦åŒ–ã•ã‚ŒãŸLogEntry
        """
        # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’datetimeã«å¤‰æ›
        timestamp = self._parse_timestamp(engine_log.get("time"))
        
        # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã®æ­£è¦åŒ–ï¼ˆå­˜åœ¨ã™ã‚‹å ´åˆï¼‰
        level = self._normalize_level(engine_log.get("level", "info"))
        
        # ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŠ½å‡º
        message = self._extract_message(engine_log)
        
        return LogEntry(
            timestamp=timestamp,
            level=level,
            message=message,
            source=engine_log.get("hostname"),
            hostname=engine_log.get("hostname"),
            metadata={
                "log_type": engine_log.get("log_type"),
                "customer_name": engine_log.get("customer_name"),
                "fqdn": engine_log.get("fqdn"),
                "year": engine_log.get("year"),
                "month": engine_log.get("month"),
                "day": engine_log.get("day"),
                "hour": engine_log.get("hour"),
                "minute": engine_log.get("minute"),
                "second": engine_log.get("second"),
                # Engineå´ã®ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãã®ã¾ã¾ä¿æŒ
                "original_fields": {
                    k: v for k, v in engine_log.items() 
                    if k not in ['time', 'log_type', 'hostname', 'customer_name', 'fqdn']
                }
            }
        )
    
    def _parse_timestamp(self, time_str: str) -> datetime:
        """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’datetimeã«å¤‰æ›"""
        from dateutil import parser as date_parser
        
        try:
            dt = date_parser.parse(time_str)
            if dt.tzinfo is None:
                dt = dt.replace(tzinfo=timezone.utc)
            return dt
        except (ValueError, TypeError):
            return datetime.now(timezone.utc)
    
    def _normalize_level(self, level: str) -> str:
        """ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«ã‚’æ­£è¦åŒ–"""
        level_lower = str(level).lower().strip()
        return self.LEVEL_MAP.get(level_lower, "info")
    
    def _extract_message(self, engine_log: dict) -> str:
        """ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’æŠ½å‡º"""
        log_type = engine_log.get("log_type")
        
        if log_type == "nginx":
            # Nginxãƒ­ã‚°ã®å ´åˆ: requestãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½¿ç”¨
            return engine_log.get("request", "")
        elif log_type == "openappsec":
            # OpenAppSecãƒ­ã‚°ã®å ´åˆ: signatureã‚’ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¨ã—ã¦ä½¿ç”¨
            return engine_log.get("signature", "WAF Detection")
        else:
            # ãã®ä»–: message ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã¾ãŸã¯ç©ºæ–‡å­—åˆ—
            return engine_log.get("message", "")
```

### 4. Time Correctorï¼ˆã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£ï¼‰

Engineå´ã‹ã‚‰é€ä¿¡ã•ã‚Œã‚‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã¯æ—¢ã«æ­£ã—ã„å½¢å¼ã§ã™ãŒã€ä»¥ä¸‹ã®è£œæ­£ã‚’è¡Œã„ã¾ã™ï¼š

```python
class TimeCorrector:
    """ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è£œæ­£ã™ã‚‹"""
    
    def __init__(
        self, 
        max_future_offset_minutes: int = 5, 
        old_log_days: int = 7
    ) -> None:
        self.max_future_offset = timedelta(minutes=max_future_offset_minutes)
        self.old_log_threshold = timedelta(days=old_log_days)
    
    def correct(self, log_entry: LogEntry) -> LogEntry:
        """
        ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’è£œæ­£
        
        1. ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ãŒãªã„å ´åˆã¯UTCã¨ä»®å®š
        2. ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãŒãªã„å ´åˆã¯å—ä¿¡æ™‚åˆ»ã‚’ä½¿ç”¨
        3. æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆ5åˆ†ä»¥ä¸Šï¼‰ã¯å—ä¿¡æ™‚åˆ»ã«è£œæ­£
        4. å¤ã™ãã‚‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰ã¯è­¦å‘Š
        """
        now = datetime.now(timezone.utc)
        
        if log_entry.timestamp is None:
            log_entry.timestamp = now
            log_entry.metadata['timestamp_source'] = 'server'
            return log_entry
        
        # ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³æƒ…å ±ã®è£œå®Œ
        if log_entry.timestamp.tzinfo is None:
            log_entry.timestamp = log_entry.timestamp.replace(tzinfo=timezone.utc)
            log_entry.metadata['timezone_assumed'] = True
        
        # æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ãƒã‚§ãƒƒã‚¯ï¼ˆ5åˆ†ä»¥ä¸Šæœªæ¥ï¼‰
        if log_entry.timestamp > now + self.max_future_offset:
            log_entry.metadata['timestamp_corrected'] = True
            log_entry.metadata['original_timestamp'] = log_entry.timestamp.isoformat()
            log_entry.timestamp = now
        
        # å¤ã™ãã‚‹ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®è­¦å‘Šï¼ˆ7æ—¥ä»¥ä¸Šå‰ï¼‰
        if log_entry.timestamp < now - self.old_log_threshold:
            log_entry.metadata['timestamp_warning'] = 'old_timestamp'
        
        return log_entry
```

### 5. Log Bufferï¼ˆãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ï¼‰

#### ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æˆ¦ç•¥

```mermaid
stateDiagram-v2
    [*] --> Receiving: ãƒ­ã‚°å—ä¿¡
    Receiving --> Buffering: ãƒ¡ãƒ¢ãƒªã«è“„ç©
    Buffering --> Flushing: æ¡ä»¶æº€ãŸã™
    Flushing --> Writing: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«æ›¸ãè¾¼ã¿
    Writing --> [*]: å®Œäº†
    
    note right of Buffering
        ãƒ•ãƒ©ãƒƒã‚·ãƒ¥æ¡ä»¶:
        - ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: 1000ä»¶
        - æ™‚é–“çµŒé: 30ç§’
        - ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡: 10MB
    end note
```

#### å®Ÿè£…æ–¹é‡

- **ãƒ¡ãƒ¢ãƒªãƒãƒƒãƒ•ã‚¡**: æœ€å¤§1000ä»¶ã¾ãŸã¯10MB
- **ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã‚¿ã‚¤ãƒŸãƒ³ã‚°**: 
  - ãƒãƒƒãƒ•ã‚¡æº€æ¯æ™‚ï¼ˆ1000ä»¶ã¾ãŸã¯10MBï¼‰
  - 30ç§’çµŒéæ™‚
  - ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚
- **ãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ï¼ˆèƒŒåœ§ï¼‰**: 
  - ãƒãƒƒãƒ•ã‚¡ãŒ90%ä»¥ä¸Šæº€æ¯ã®å ´åˆã€æ–°è¦ãƒ­ã‚°ã‚’æ‹’å¦ï¼ˆHTTP 503ï¼‰
  - Engine Fluentdã«ãƒªãƒˆãƒ©ã‚¤ã‚’ä¿ƒã™
  - ãƒ¡ãƒ¢ãƒªæ¯æ¸‡ã‚’é˜²æ­¢
- **éåŒæœŸå‡¦ç†**: ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸æ›¸ãè¾¼ã¿ã¯éåŒæœŸã§å®Ÿè¡Œï¼ˆã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã‚’ãƒ–ãƒ­ãƒƒã‚¯ã—ãªã„ï¼‰

#### å®Ÿè£…ä¾‹

```python
class BufferFullError(Exception):
    """ãƒãƒƒãƒ•ã‚¡ãŒæº€æ¯ã®å ´åˆã«ç™ºç”Ÿã™ã‚‹ä¾‹å¤–"""
    pass

class LogBuffer:
    """ãƒ­ã‚°ã‚’ãƒ¡ãƒ¢ãƒªä¸Šã§ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°ã™ã‚‹"""
    
    def __init__(
        self,
        max_size: int = 1000,
        max_age_seconds: int = 30,
        max_memory_mb: int = 10,
        storage=None,
    ) -> None:
        self.buffer: List[LogEntry] = []
        self.max_size = max_size
        self.max_age_seconds = max_age_seconds
        self.max_memory_bytes = max_memory_mb * 1024 * 1024
        self.storage = storage
        self.lock = asyncio.Lock()
        self.last_flush = datetime.now(timezone.utc)

    async def add_batch(self, log_entries: List[LogEntry]) -> None:
        """
        ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒãƒƒãƒ•ã‚¡ã«è¿½åŠ 
        
        Raises:
            BufferFullError: ãƒãƒƒãƒ•ã‚¡ãŒæº€æ¯ã®å ´åˆ
        """
        async with self.lock:
            # ãƒãƒƒãƒ•ã‚¡æº€æ¯ãƒã‚§ãƒƒã‚¯ï¼ˆãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ï¼‰
            if self._is_buffer_full(len(log_entries)):
                raise BufferFullError(
                    f"Buffer is full: {len(self.buffer)} entries, "
                    f"{self._get_buffer_size_bytes()} bytes"
                )
            
            self.buffer.extend(log_entries)
            
            # è‡ªå‹•ãƒ•ãƒ©ãƒƒã‚·ãƒ¥æ¡ä»¶ãƒã‚§ãƒƒã‚¯
            if self._should_flush():
                await self.flush()
    
    def _is_buffer_full(self, additional_entries: int = 0) -> bool:
        """
        ãƒãƒƒãƒ•ã‚¡ãŒæº€æ¯ã‹åˆ¤å®šï¼ˆãƒãƒƒã‚¯ãƒ—ãƒ¬ãƒƒã‚·ãƒ£ãƒ¼ç”¨ï¼‰
        
        Args:
            additional_entries: è¿½åŠ ã—ã‚ˆã†ã¨ã—ã¦ã„ã‚‹ã‚¨ãƒ³ãƒˆãƒªæ•°
            
        Returns:
            ãƒãƒƒãƒ•ã‚¡ãŒæº€æ¯ã®å ´åˆTrue
        """
        # ã‚¨ãƒ³ãƒˆãƒªæ•°ãƒã‚§ãƒƒã‚¯ï¼ˆä½™è£•ã‚’æŒãŸã›ã¦90%ã§æº€æ¯ã¨ã¿ãªã™ï¼‰
        if (len(self.buffer) + additional_entries) >= self.max_size * 0.9:
            return True
        
        # ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯ï¼ˆæ¦‚ç®—ï¼‰
        current_size = self._get_buffer_size_bytes()
        if current_size >= self.max_memory_bytes * 0.9:
            return True
        
        return False
    
    def _get_buffer_size_bytes(self) -> int:
        """
        ãƒãƒƒãƒ•ã‚¡ã®ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºã‚’æ¦‚ç®—ï¼ˆãƒã‚¤ãƒˆï¼‰
        
        ã‚ˆã‚Šæ­£ç¢ºãªè¦‹ç©ã‚‚ã‚Šã®ãŸã‚ã€å„ã‚¨ãƒ³ãƒˆãƒªã®JSONã‚µã‚¤ã‚ºã‚’è¨ˆç®—
        """
        if not self.buffer:
            return 0
        
        # ã‚µãƒ³ãƒ—ãƒ«ãƒ™ãƒ¼ã‚¹ã®è¦‹ç©ã‚‚ã‚Šï¼ˆãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ã¨ã®ãƒãƒ©ãƒ³ã‚¹ï¼‰
        # æœ€åˆã®10ã‚¨ãƒ³ãƒˆãƒªã®å¹³å‡ã‚µã‚¤ã‚ºã‹ã‚‰å…¨ä½“ã‚’æ¨å®š
        sample_size = min(10, len(self.buffer))
        total_sample_size = 0
        
        for entry in self.buffer[:sample_size]:
            # JSONæ–‡å­—åˆ—ã®ã‚µã‚¤ã‚ºã‚’è¨ˆç®—
            try:
                json_str = json.dumps(entry.to_dict(), ensure_ascii=False)
                total_sample_size += len(json_str.encode('utf-8'))
            except Exception:
                # ã‚¨ãƒ©ãƒ¼æ™‚ã¯å®‰å…¨å´ã®è¦‹ç©ã‚‚ã‚Šï¼ˆ1ã‚¨ãƒ³ãƒˆãƒª=2KBï¼‰
                total_sample_size += 2048
        
        # å¹³å‡ã‚µã‚¤ã‚ºã‚’è¨ˆç®—ã—ã¦å…¨ä½“ã‚’æ¨å®š
        avg_size = total_sample_size / sample_size if sample_size > 0 else 2048
        return int(avg_size * len(self.buffer))
    
    def _should_flush(self) -> bool:
        """ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ã™ã¹ãã‹åˆ¤å®š"""
        # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if len(self.buffer) >= self.max_size:
            return True
        
        # ãƒ¡ãƒ¢ãƒªã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
        if self._get_buffer_size_bytes() >= self.max_memory_bytes:
            return True
        
        # æ™‚é–“ãƒã‚§ãƒƒã‚¯
        age = (datetime.now(timezone.utc) - self.last_flush).total_seconds()
        if age >= self.max_age_seconds:
            return True
        
        return False
    
    def size(self) -> int:
        """ç¾åœ¨ã®ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã‚’å–å¾—"""
        return len(self.buffer)
    
    async def flush(self) -> None:
        """ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«æ›¸ãè¾¼ã‚€ï¼ˆéåŒæœŸï¼‰"""
        if not self.buffer or self.storage is None:
            return
        
        async with self.lock:
            logs_to_write = self.buffer.copy()
            self.buffer.clear()
            self.last_flush = datetime.now(timezone.utc)
        
        # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã«éåŒæœŸæ›¸ãè¾¼ã¿
        await self.storage.write_batch(logs_to_write)
    
    async def close(self) -> None:
        """ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã«ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥"""
        await self.flush()
```

### 6. Storageï¼ˆã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼‰

#### ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ï¼ˆåˆæœŸå®Ÿè£…ï¼‰

Engineå´ã®è¨­è¨ˆã‚’å‚è€ƒã«ã€ãƒ­ã‚°ã‚’æ§‹é€ åŒ–ã—ã¦ä¿å­˜ï¼š

**ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ **:
```
logs/
â”œâ”€â”€ {customer_name}/
â”‚   â”œâ”€â”€ {log_type}/
â”‚   â”‚   â”œâ”€â”€ {fqdn}/
â”‚   â”‚   â”‚   â”œâ”€â”€ {year}/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ {month}/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ {day}/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ {hour}.log
```

**ä¾‹**:
```
logs/
â”œâ”€â”€ customer-a/
â”‚   â”œâ”€â”€ nginx/
â”‚   â”‚   â”œâ”€â”€ example.com/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2026/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 02/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 17/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 13.log
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 14.log
â”‚   â”œâ”€â”€ openappsec/
â”‚   â”‚   â”œâ”€â”€ example.com/
â”‚   â”‚   â”‚   â”œâ”€â”€ 2026/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 02/
â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 17/
â”‚   â”‚   â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 13.log
```

**ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼**: JSON Linesï¼ˆ1è¡Œ1ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªï¼‰

```jsonl
{"log_id":"uuid","timestamp":"2026-02-17T13:30:00.123Z","level":"info","source":"waf-engine-01","message":"GET /api/users HTTP/1.1","metadata":{...}}
{"log_id":"uuid","timestamp":"2026-02-17T13:30:01.234Z","level":"warning","source":"waf-engine-01","message":"Rate limit exceeded","metadata":{...}}
```

#### éåŒæœŸI/Oå®Ÿè£…

**é‡è¦**: éåŒæœŸI/Oã‚’ä½¿ç”¨ã—ã¦ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã®ãƒ–ãƒ­ãƒƒã‚¯ã‚’å›é¿

```python
import aiofiles
from pathlib import Path
from typing import List

class FileStorage:
    """ãƒ•ã‚¡ã‚¤ãƒ«ãƒ™ãƒ¼ã‚¹ã®ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ï¼ˆéåŒæœŸI/Oï¼‰"""
    
    def __init__(self, base_path: str = "logs") -> None:
        self.base_path = Path(base_path)
    
    def _get_log_file_path(self, log_entry: LogEntry) -> Path:
        """
        ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã‚’ç”Ÿæˆ
        
        ãƒ‘ã‚¹æ§‹é€ : 
        logs/{customer_name}/{log_type}/{fqdn}/{year}/{month}/{day}/{hour}.log
        
        ä¾‹:
        logs/customer-a/nginx/example.com/2026/02/17/13.log
        """
        ts = log_entry.timestamp
        metadata = log_entry.metadata
        
        customer_name = metadata.get('customer_name', 'default')
        log_type = metadata.get('log_type', 'unknown')
        fqdn = metadata.get('fqdn', 'unknown')
        
        return (
            self.base_path 
            / customer_name 
            / log_type 
            / fqdn
            / str(ts.year)
            / f"{ts.month:02d}"
            / f"{ts.day:02d}"
            / f"{ts.hour:02d}.log"
        )
    
    async def write_batch(self, log_entries: List[LogEntry]) -> None:
        """
        ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒãƒƒãƒã§æ›¸ãè¾¼ã‚€ï¼ˆéåŒæœŸI/Oï¼‰
        
        Args:
            log_entries: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ•ã‚¡ã‚¤ãƒ«åˆ¥ã«ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°
        grouped: dict[Path, List[LogEntry]] = {}
        for entry in log_entries:
            path = self._get_log_file_path(entry)
            if path not in grouped:
                grouped[path] = []
            grouped[path].append(entry)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«ã”ã¨ã«æ›¸ãè¾¼ã¿ï¼ˆéåŒæœŸï¼‰
        for path, entries in grouped.items():
            await self._write_to_file(path, entries)
    
    async def _write_to_file(self, path: Path, log_entries: List[LogEntry]) -> None:
        """
        æŒ‡å®šã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã«ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’æ›¸ãè¾¼ã‚€ï¼ˆéåŒæœŸï¼‰
        
        Args:
            path: ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
            log_entries: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ãƒªã‚¹ãƒˆ
        """
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        path.parent.mkdir(parents=True, exist_ok=True)
        
        # aiofilesã‚’ä½¿ç”¨ã—ãŸéåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«I/O
        async with aiofiles.open(path, 'a', encoding='utf-8') as f:
            for entry in log_entries:
                line = json.dumps(entry.to_dict(), ensure_ascii=False) + '\n'
                await f.write(line)
```

---

## ãƒ‡ãƒ¼ã‚¿æ§‹é€ 

### æ­£è¦åŒ–å¾Œã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª

```python
from dataclasses import dataclass, field
from datetime import datetime, timezone
from typing import Optional, Dict, Any
import uuid

@dataclass
class LogEntry:
    """æ­£è¦åŒ–å¾Œã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒª"""
    
    # å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    timestamp: datetime      # UTCã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—
    level: str              # ãƒ­ã‚°ãƒ¬ãƒ™ãƒ« (debug, info, warning, error, critical)
    message: str            # ãƒ­ã‚°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸
    
    # ã‚ªãƒ—ã‚·ãƒ§ãƒ³ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    source: Optional[str] = None          # ãƒ­ã‚°ã‚½ãƒ¼ã‚¹ï¼ˆwaf-engine-01ç­‰ï¼‰
    hostname: Optional[str] = None        # ãƒ›ã‚¹ãƒˆå
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ï¼ˆEngineå´ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸæƒ…å ±ã‚’ä¿æŒï¼‰
    metadata: Dict[str, Any] = field(default_factory=dict)
    # metadataä¾‹:
    # {
    #   "log_type": "nginx" | "openappsec",
    #   "customer_name": "customer-a",
    #   "fqdn": "example.com",
    #   "year": "2026",
    #   "month": "02",
    #   "day": "17",
    #   "hour": "13",
    #   "minute": "30",
    #   "second": "45",
    #   "original_fields": {
    #     ... Engineå´ã®ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰
    #   }
    # }
    
    # å†…éƒ¨ç®¡ç†
    received_at: datetime = field(default_factory=lambda: datetime.now(timezone.utc))
    log_id: str = field(default_factory=lambda: str(uuid.uuid4()))
    
    def to_dict(self) -> dict:
        """è¾æ›¸å½¢å¼ã«å¤‰æ›"""
        return {
            "log_id": self.log_id,
            "timestamp": self.timestamp.isoformat(),
            "level": self.level,
            "message": self.message,
            "source": self.source,
            "hostname": self.hostname,
            "metadata": self.metadata,
            "received_at": self.received_at.isoformat(),
        }
```

---

## å®Ÿè£…è¨ˆç”»

### Phase 1: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ ã®ä½œæˆ

#### 1.1 ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ 

```
MrWebDefence-LogServer/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ models.py        # ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«ï¼ˆLogEntryï¼‰
â”‚   â”œâ”€â”€ server/          # Webã‚µãƒ¼ãƒãƒ¼ï¼ˆFastAPIï¼‰
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ app.py       # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ parser/          # ãƒ­ã‚°ãƒ‘ãƒ¼ã‚µãƒ¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ log_parser.py
â”‚   â”‚   â””â”€â”€ normalizer.py
â”‚   â”œâ”€â”€ corrector/       # ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ time_corrector.py
â”‚   â”œâ”€â”€ buffer/          # ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ log_buffer.py
â”‚   â””â”€â”€ storage/         # ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ file_storage.py
â”‚       â””â”€â”€ db_storage.py (å°†æ¥)
â”œâ”€â”€ config/
â”‚   â””â”€â”€ server.yaml      # ã‚µãƒ¼ãƒãƒ¼è¨­å®š
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ unit/
â”‚   â”œâ”€â”€ integration/
â”‚   â””â”€â”€ fixtures/
â”‚       â”œâ”€â”€ nginx_log_samples.json
â”‚       â””â”€â”€ openappsec_log_samples.json
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ design/
â”‚       â””â”€â”€ MWD-53-log-collection.md
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ dev-server.sh
â”‚   â””â”€â”€ run-tests.sh
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

#### 1.2 ä¾å­˜é–¢ä¿‚

```toml
[tool.poetry]
name = "mrwebdefence-logserver"
version = "0.1.0"
description = "MrWebDefence Log Collection and Management Server"

[tool.poetry.dependencies]
python = "^3.12"
fastapi = "^0.109.0"
uvicorn = {extras = ["standard"], version = "^0.27.0"}
pydantic = "^2.6.0"
python-dateutil = "^2.8.2"
pyyaml = "^6.0.1"
aiofiles = "^23.2.1"  # éåŒæœŸãƒ•ã‚¡ã‚¤ãƒ«I/O

[tool.poetry.group.dev.dependencies]
pytest = "^8.0.0"
pytest-asyncio = "^0.23.0"
black = "^24.1.0"
flake8 = "^7.0.0"
mypy = "^1.8.0"
httpx = "^0.26.0"  # ãƒ†ã‚¹ãƒˆç”¨HTTP ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ
```

### Phase 2: ãƒ‡ãƒ¼ã‚¿ãƒ¢ãƒ‡ãƒ«å®Ÿè£…

`src/models.py`ã«LogEntryãƒ‡ãƒ¼ã‚¿ã‚¯ãƒ©ã‚¹ã‚’å®Ÿè£…ï¼ˆå‰è¿°ã®å®Ÿè£…ã‚’ä½¿ç”¨ï¼‰

### Phase 3: Log Receiverå®Ÿè£…

`src/server/app.py`ã«FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè£…ï¼ˆå‰è¿°ã®å®Ÿè£…ã‚’ä½¿ç”¨ï¼‰

### Phase 4: Parser & Normalizerå®Ÿè£…

- `src/parser/log_parser.py`: Engineå´ã®ãƒ­ã‚°ã‚’ãƒ‘ãƒ¼ã‚¹
- `src/parser/normalizer.py`: LogEntryã«æ­£è¦åŒ–

### Phase 5: Time Correctorå®Ÿè£…

`src/corrector/time_corrector.py`ã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£ã‚’å®Ÿè£…

### Phase 6: Bufferå®Ÿè£…

`src/buffer/log_buffer.py`ã«ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°æ©Ÿèƒ½ã‚’å®Ÿè£…

### Phase 7: Storageå®Ÿè£…

`src/storage/file_storage.py`ã«ãƒ•ã‚¡ã‚¤ãƒ«ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã‚’å®Ÿè£…ï¼ˆaiofilesä½¿ç”¨ï¼‰

---

## ãƒ†ã‚¹ãƒˆè¨ˆç”»

### Unit Tests

#### 1. Log Parser Tests (`tests/unit/test_log_parser.py`)
- Engineå´ã®ãƒ­ã‚°å½¢å¼ã®ãƒ‘ãƒ¼ã‚¹
- å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®æ¤œè¨¼
- ä¸æ­£ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°

#### 2. Normalizer Tests (`tests/unit/test_normalizer.py`)
- Engineå´ã®ãƒ­ã‚°ã‹ã‚‰LogEntryã¸ã®å¤‰æ›
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã®ãƒ‘ãƒ¼ã‚¹
- ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®æŠ½å‡ºï¼ˆlog_typeåˆ¥ï¼‰
- ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®æ•´ç†

#### 3. Time Corrector Tests (`tests/unit/test_time_corrector.py`)
- ã‚¿ã‚¤ãƒ ã‚¾ãƒ¼ãƒ³è£œæ­£
- æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è£œæ­£
- ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æ¬ ææ™‚ã®è£œå®Œ

#### 4. Buffer Tests (`tests/unit/test_log_buffer.py`)
- ãƒãƒƒãƒ•ã‚¡ãƒªãƒ³ã‚°å‹•ä½œ
- è‡ªå‹•ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼ˆã‚µã‚¤ã‚ºãƒ»æ™‚é–“ï¼‰
- ã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã®ãƒ•ãƒ©ãƒƒã‚·ãƒ¥

#### 5. Storage Tests (`tests/unit/test_file_storage.py`)
- ãƒ•ã‚¡ã‚¤ãƒ«æ›¸ãè¾¼ã¿ï¼ˆéåŒæœŸI/Oï¼‰
- ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆï¼ˆEngineå´ã®æ§‹é€ ã«æº–æ‹ ï¼‰
- ãƒãƒƒãƒæ›¸ãè¾¼ã¿

### Integration Tests

#### 1. API Endpoint Tests (`tests/integration/test_api.py`)
- Engineå´ã®ãƒ­ã‚°å—ä¿¡ï¼ˆå˜ä¸€ãƒ­ã‚°ï¼‰
- ãƒãƒƒãƒãƒ­ã‚°å—ä¿¡
- ã‚¨ãƒ©ãƒ¼ã‚±ãƒ¼ã‚¹ï¼ˆå¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰æ¬ å¦‚ç­‰ï¼‰

#### 2. End-to-End Tests (`tests/integration/test_e2e.py`)
- Engine Fluentd â†’ Log Server â†’ Storage
- å¤§é‡ãƒ­ã‚°ã®å‡¦ç†
- ã‚¨ãƒ©ãƒ¼ãƒªã‚«ãƒãƒªãƒ¼

### ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ï¼ˆFixturesï¼‰

#### Nginxãƒ­ã‚°ã‚µãƒ³ãƒ—ãƒ« (`tests/fixtures/nginx_log_samples.json`)

```json
[
  {
    "time": "2026-02-17T13:30:00+09:00",
    "remote_addr": "192.168.1.100",
    "request": "GET /api/users HTTP/1.1",
    "status": 200,
    "body_bytes_sent": 1234,
    "request_time": 0.123,
    "host": "example.com",
    "customer_name": "customer-a",
    "log_type": "nginx",
    "hostname": "waf-engine-01",
    "fqdn": "example.com",
    "year": "2026",
    "month": "02",
    "day": "17",
    "hour": "13"
  }
]
```

#### OpenAppSecãƒ­ã‚°ã‚µãƒ³ãƒ—ãƒ« (`tests/fixtures/openappsec_log_samples.json`)

```json
[
  {
    "time": "2026-02-17T13:30:00+09:00",
    "host": "example.com",
    "protectionName": "Threat Prevention Basic",
    "signature": "SQL Injection Attempt",
    "ruleName": "rule_001",
    "sourceIP": "192.168.1.100",
    "requestUri": "/admin/login",
    "log_type": "openappsec",
    "source": "waf-engine",
    "hostname": "waf-engine-01",
    "customer_name": "customer-a",
    "fqdn": "example.com",
    "year": "2026",
    "month": "02",
    "day": "17",
    "hour": "13"
  }
]
```

---

## éæ©Ÿèƒ½è¦ä»¶

### ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹

- **ã‚¹ãƒ«ãƒ¼ãƒ—ãƒƒãƒˆ**: 1000 logs/secä»¥ä¸Š
- **ãƒ¬ã‚¤ãƒ†ãƒ³ã‚·**: 
  - å—ä¿¡ã‹ã‚‰ãƒãƒƒãƒ•ã‚¡è¿½åŠ ã¾ã§: 10msä»¥å†…
  - ãƒãƒƒãƒ•ã‚¡ã‹ã‚‰ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸ã¾ã§: 100msä»¥å†…ï¼ˆãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰å‡¦ç†ï¼‰
- **ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡**: 100MBä»¥å†…ï¼ˆãƒãƒƒãƒ•ã‚¡å«ã‚€ï¼‰
- **åŒæ™‚æ¥ç¶šæ•°**: 100æ¥ç¶šä»¥ä¸Š

### ä¿¡é ¼æ€§

- **ãƒ‡ãƒ¼ã‚¿ãƒ­ã‚¹**: ã‚¼ãƒ­ï¼ˆã‚·ãƒ£ãƒƒãƒˆãƒ€ã‚¦ãƒ³æ™‚ã‚‚ãƒãƒƒãƒ•ã‚¡ã‚’ãƒ•ãƒ©ãƒƒã‚·ãƒ¥ï¼‰
- **å¯ç”¨æ€§**: 99.9%ä»¥ä¸Š
- **å†èµ·å‹•æ™‚é–“**: 5ç§’ä»¥å†…
- **ã‚¨ãƒ©ãƒ¼ãƒªã‚«ãƒãƒªãƒ¼**: è‡ªå‹•ãƒªãƒˆãƒ©ã‚¤ã€ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°å‡ºåŠ›

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

- **å…¥åŠ›æ¤œè¨¼**: 
  - å¿…é ˆãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å­˜åœ¨ç¢ºèª
  - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®å‹ãƒã‚§ãƒƒã‚¯ï¼ˆæ–‡å­—åˆ—å‹ã®ç¢ºèªï¼‰
  - ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰å€¤ã®é•·ã•åˆ¶é™ï¼ˆDoSæ”»æ’ƒå¯¾ç­–ï¼‰
    - é€šå¸¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: æœ€å¤§1KB
    - ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: æœ€å¤§10KB
- **èªè¨¼**: APIã‚­ãƒ¼ãƒ™ãƒ¼ã‚¹ã®èªè¨¼ï¼ˆç’°å¢ƒå¤‰æ•°ã§ç®¡ç†ã€å°†æ¥å®Ÿè£…ï¼‰
- **æš—å·åŒ–**: TLS/SSLå¯¾å¿œï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
- **ãƒ¬ãƒ¼ãƒˆåˆ¶é™**: éè² è·é˜²æ­¢ï¼ˆå°†æ¥å®Ÿè£…ï¼‰
- **ã‚¨ãƒ©ãƒ¼æƒ…å ±ã®åˆ¶é™**: è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’å¤–éƒ¨ã«æ¼ã‚‰ã•ãªã„ï¼ˆInternal server errorã¨ã—ã¦è¿”ã™ï¼‰

### é‹ç”¨æ€§

- **ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯**: GET /health
- **ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°**: ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã€å—ä¿¡ãƒ­ã‚°æ•°
- **ãƒ­ã‚°å‡ºåŠ›**: æ§‹é€ åŒ–ãƒ­ã‚°ï¼ˆJSONå½¢å¼ï¼‰
- **è¨­å®šç®¡ç†**: YAMLãƒ•ã‚¡ã‚¤ãƒ«ã«ã‚ˆã‚‹è¨­å®š

---

## è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«

### server.yaml

```yaml
server:
  host: 0.0.0.0
  http_port: 8080
  workers: 4

buffer:
  max_size: 1000           # ãƒãƒƒãƒ•ã‚¡ã®æœ€å¤§ã‚µã‚¤ã‚ºï¼ˆä»¶æ•°ï¼‰
  max_age_seconds: 30      # ãƒãƒƒãƒ•ã‚¡ã®æœ€å¤§ä¿æŒæ™‚é–“ï¼ˆç§’ï¼‰
  max_memory_mb: 10        # ãƒãƒƒãƒ•ã‚¡ã®æœ€å¤§ãƒ¡ãƒ¢ãƒªä½¿ç”¨é‡ï¼ˆMBï¼‰

storage:
  type: file
  base_path: logs
  # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ : {customer_name}/{log_type}/{fqdn}/{year}/{month}/{day}/{hour}.log

time_correction:
  max_future_offset_minutes: 5    # æœªæ¥ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—è¨±å®¹ç¯„å›²ï¼ˆåˆ†ï¼‰
  old_log_warning_days: 7         # å¤ã„ãƒ­ã‚°è­¦å‘Šé–¾å€¤ï¼ˆæ—¥ï¼‰

logging:
  level: info
  format: json
```

---

## é‹ç”¨

### èµ·å‹•æ–¹æ³•

```bash
# é–‹ç™ºç’°å¢ƒ
poetry run python -m src.server.app

# æœ¬ç•ªç’°å¢ƒï¼ˆ4ãƒ¯ãƒ¼ã‚«ãƒ¼ï¼‰
poetry run uvicorn src.server.app:app \
  --host 0.0.0.0 \
  --port 8080 \
  --workers 4
```

### ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª

```bash
# ãƒ­ã‚°ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’ç¢ºèª
ls -R logs/

# ç‰¹å®šã®ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç¢ºèª
cat logs/customer-a/nginx/example.com/2026/02/17/13.log | jq .

# ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªæ•°ã‚’ã‚«ã‚¦ãƒ³ãƒˆ
find logs/ -type f -name "*.log" -exec wc -l {} + | tail -1
```

### ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°

```bash
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8080/health

# ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚ºã®ç›£è¦–
watch -n 5 'curl -s http://localhost:8080/health | jq .buffer_size'
```

### ãƒ­ã‚°ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–

Engineå´ã®logrotateè¨­å®šï¼ˆæ¯æ—¥ãƒ­ãƒ¼ãƒ†ãƒ¼ãƒˆï¼‰ã¨é€£æºã—ã€å¤ã„ãƒ­ã‚°ã‚’ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼š

```bash
# 30æ—¥ä»¥ä¸Šå‰ã®ãƒ­ã‚°ã‚’åœ§ç¸®
find logs/ -type f -name "*.log" -mtime +30 -exec gzip {} \;

# 90æ—¥ä»¥ä¸Šå‰ã®ãƒ­ã‚°ã‚’å‰Šé™¤
find logs/ -type f -name "*.log.gz" -mtime +90 -delete
```

---

## å°†æ¥ã®æ‹¡å¼µ

### çŸ­æœŸï¼ˆPhase 2ï¼‰

1. **èªè¨¼æ©Ÿèƒ½**: APIã‚­ãƒ¼ãƒ™ãƒ¼ã‚¹ã®èªè¨¼
2. **ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ**: Prometheusãƒ¡ãƒˆãƒªã‚¯ã‚¹å‡ºåŠ›
3. **ãƒ­ã‚°æ¤œç´¢API**: åŸºæœ¬çš„ãªãƒ­ã‚°æ¤œç´¢æ©Ÿèƒ½

### ä¸­æœŸï¼ˆPhase 3ï¼‰

1. **ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¸**: PostgreSQL, TimescaleDBå¯¾å¿œ
2. **ãƒ­ã‚°é›†ç´„**: è¤‡æ•°ã®Engine instanceã‹ã‚‰ã®ãƒ­ã‚°å—ä¿¡
3. **ã‚¢ãƒ©ãƒ¼ãƒˆæ©Ÿèƒ½**: ç‰¹å®šãƒ‘ã‚¿ãƒ¼ãƒ³æ¤œå‡ºæ™‚ã®é€šçŸ¥

### é•·æœŸï¼ˆPhase 4ï¼‰

1. **Elasticsearché€£æº**: ãƒ­ã‚°æ¤œç´¢ãƒ»å¯è¦–åŒ–
2. **Grafana/Kibanaé€£æº**: ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰
3. **åˆ†æ•£å‡¦ç†**: è¤‡æ•°ãƒãƒ¼ãƒ‰ã§ã®è² è·åˆ†æ•£
4. **Kuberneteså¯¾å¿œ**: Helm Chartã€StatefulSet

---

## Engineå´ã¨ã®é€£æºä»•æ§˜

### 1. HTTPã‚¨ãƒ³ãƒ‰ãƒã‚¤ãƒ³ãƒˆ

**URL**: `http://log-server:8080/api/logs`ï¼ˆDocker Composeç’°å¢ƒï¼‰

**ãƒ¡ã‚½ãƒƒãƒ‰**: POST

**Content-Type**: application/json

**Body**: å˜ä¸€ãƒ­ã‚°ã¾ãŸã¯ãƒ­ã‚°ã®é…åˆ—

### 2. Engineå´ã®Fluentdè¨­å®šä¾‹

```aconf
# Engineå´ï¼ˆdocker/fluentd/fluent.confï¼‰

<match {nginx,openappsec}.**>
  @type http
  endpoint http://log-server:8080/api/logs
  http_method post
  <headers>
    Content-Type application/json
  </headers>
  <buffer>
    @type file
    path /var/log/fluentd/buffer
    flush_interval 5s
    retry_type exponential_backoff
    retry_wait 1s
    retry_max_interval 60s
    retry_timeout 60m
  </buffer>
  <format>
    @type json
  </format>
</match>
```

### 3. Engineå´ã®ã‚¿ã‚°è¨­è¨ˆã¨ã®å¯¾å¿œ

Engineå´ã®ã‚¿ã‚°è¨­è¨ˆï¼ˆã‚·ãƒ³ãƒ—ãƒ«ãªã‚¿ã‚°æ§‹é€ ï¼‰ã‚’ç¶­æŒï¼š

| Engineå´ã‚¿ã‚° | LogServerå—ä¿¡å†…å®¹ | LogServerå†…éƒ¨å‡¦ç† |
|-------------|-------------------|------------------|
| `nginx.access` | `log_type: "nginx"` | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: `request`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ |
| `nginx.error` | `log_type: "nginx"` | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: `message`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ |
| `openappsec.detection` | `log_type: "openappsec"` | ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: `signature`ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ |

### 4. ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®ä¿æŒ

Engineå´ã‹ã‚‰é€ä¿¡ã•ã‚ŒãŸã™ã¹ã¦ã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’ä¿æŒï¼š

- `customer_name`: é¡§å®¢å
- `fqdn`: FQDN
- `hostname`: ãƒ›ã‚¹ãƒˆå
- `year`, `month`, `day`, `hour`, `minute`, `second`: ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—æƒ…å ±
- ãã®ä»–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰: `metadata.original_fields`ã«ä¿å­˜

---

## å‚è€ƒè³‡æ–™

### Engineå´è¨­è¨ˆæ›¸

- [MWD-40: Fluentdè¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«åŒ–è¨ˆç”»](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-fluentd-modularization-plan.md)
- [MWD-40: ãƒ­ã‚°è»¢é€æ©Ÿèƒ½å®Ÿè£… å®Ÿè£…è¨­è¨ˆæ›¸](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-implementation-plan.md)
- [MWD-40: ãƒ­ã‚°é€£æºæ–¹æ³•æ¯”è¼ƒæ¤œè¨](https://github.com/kencom2400/MrWebDefence-Engine/blob/main/docs/design/MWD-40-log-integration-analysis.md)

### æŠ€è¡“ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [FastAPI Documentation](https://fastapi.tiangolo.com/)
- [aiofiles Documentation](https://github.com/Tinche/aiofiles)
- [Pydantic Documentation](https://docs.pydantic.dev/)
- [Fluentdå…¬å¼ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ](https://docs.fluentd.org/)
